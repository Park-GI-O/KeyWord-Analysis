{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5cd81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.activations import relu, sigmoid\n",
    "from tensorflow.keras.layers import Dense, Dropout, Layer, Embedding, MaxPool1D, Conv1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb01a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "TRAIN_Q1_DATA = 'q1_train.npy'\n",
    "TRAIN_Q2_DATA = 'q2_train.npy'\n",
    "TRAIN_LABEL_DATA = 'label_train.npy'\n",
    "DATA_CONFIGS = 'data_configs.npy'\n",
    "\n",
    "q1_data = np.load(open(DATA_IN_PATH + TRAIN_Q1_DATA, 'rb'))\n",
    "q2_data = np.load(open(DATA_IN_PATH + TRAIN_Q2_DATA, 'rb'))\n",
    "labels = np.load(open(DATA_IN_PATH + TRAIN_LABEL_DATA, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1cf8ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEmbedding(Layer) :\n",
    "    def __init__(self, **kargs) :\n",
    "        super(SentenceEmbedding, self).__init__()\n",
    "        \n",
    "        self.conv = Conv1D(kargs['conv_num_filters'], kargs['conv_window_size'], activation=relu, padding='same')\n",
    "        self.max_pool = MaxPool1D(kargs['max_pool_seq_len'], 1)\n",
    "        self.dense = Dense(kargs['sent_embedding_dimension'], activation=relu)\n",
    "        \n",
    "    def call(self, x) :\n",
    "        x = self.conv(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.dense(x)\n",
    "        \n",
    "        return tf.squeeze(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947cb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceSimilarityModel(tf.keras.Model) :\n",
    "    def __init__(self, **kargs) :\n",
    "        super(SentenceSimilarityModel, self).__init__(name=kargs['model_name'])\n",
    "        \n",
    "        self.word_embedding = Embedding(kargs['vocab_size'], kargs['word_embedding_dimension'])\n",
    "        self.base_encoder = SentenceEmbedding(**kargs)\n",
    "        self.hypo_encoder = SentenceEmbedding(**kargs)\n",
    "        self.dense = Dense(kargs['hidden_dimension'], activation=relu)\n",
    "        self.logit = Dense(1, activation=sigmoid)\n",
    "        self.dropout = Dropout(kargs['dropout_rate'])\n",
    "        \n",
    "    def call(self, x) :\n",
    "        x1, x2 = x\n",
    "        b_x = self.word_embedding(x1)\n",
    "        h_x = self.word_embedding(x2)\n",
    "        b_x = self.dropout(b_x)\n",
    "        h_x = self.dropout(h_x)\n",
    "        \n",
    "        b_x = self.base_encoder(b_x)\n",
    "        h_x = self.hypo_encoder(h_x)\n",
    "        \n",
    "        e_x = tf.concat([b_x, h_x], -1)\n",
    "        e_x = self.dense(e_x)\n",
    "        e_x = self.dropout(e_x)\n",
    "        \n",
    "        return self.logit(e_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a81a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn_similarity'\n",
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 100\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = 31\n",
    "\n",
    "kargs = {'model_name':model_name,\n",
    "         'vocab_size' : prepro_configs['vocab_size'], \n",
    "         'word_embedding_dimension': 100,\n",
    "         'conv_num_filters' : 300,\n",
    "         'conv_window_size': 3,\n",
    "         'max_pool_seq_len' : MAX_LEN,\n",
    "         'sent_embedding_dimension' : 128,\n",
    "         'dropout_rate': 0.2,\n",
    "         'hidden_dimension': 200,\n",
    "         'output_dimension': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7338ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceSimilarityModel(**kargs)\n",
    "\n",
    "model.compile(optimizer=Adam(1e-3), loss=BinaryCrossentropy(), metrics=BinaryAccuracy(name='accuracy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15cddb86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/cnn_similarity -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir) :\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else :\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b1df61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.7388\n",
      "Epoch 1: val_accuracy improved from -inf to 0.71929, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 187s 710ms/step - loss: 0.5286 - accuracy: 0.7388 - val_loss: 0.5310 - val_accuracy: 0.7193\n",
      "Epoch 2/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.4330 - accuracy: 0.7975\n",
      "Epoch 2: val_accuracy improved from 0.71929 to 0.74817, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 194s 738ms/step - loss: 0.4330 - accuracy: 0.7975 - val_loss: 0.4942 - val_accuracy: 0.7482\n",
      "Epoch 3/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.8469\n",
      "Epoch 3: val_accuracy improved from 0.74817 to 0.78274, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 190s 723ms/step - loss: 0.3407 - accuracy: 0.8469 - val_loss: 0.4991 - val_accuracy: 0.7827\n",
      "Epoch 4/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.8877\n",
      "Epoch 4: val_accuracy improved from 0.78274 to 0.84032, saving model to ./data_out/cnn_similarity\\weights.h5\n",
      "263/263 [==============================] - 164s 623ms/step - loss: 0.2607 - accuracy: 0.8877 - val_loss: 0.4506 - val_accuracy: 0.8403\n",
      "Epoch 5/100\n",
      "263/263 [==============================] - ETA: 0s - loss: 0.2072 - accuracy: 0.9126\n",
      "Epoch 5: val_accuracy did not improve from 0.84032\n",
      "263/263 [==============================] - 160s 609ms/step - loss: 0.2072 - accuracy: 0.9126 - val_loss: 0.5806 - val_accuracy: 0.8030\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((q1_data, q2_data), labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d1e49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
